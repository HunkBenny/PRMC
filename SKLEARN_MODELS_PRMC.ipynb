{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22334,"status":"ok","timestamp":1685455149271,"user":{"displayName":"Samuel Bakker","userId":"04317401039199357493"},"user_tz":-120},"id":"wm61KNeirI03","outputId":"fcec1a74-d454-4353-bf45-2ce7120576ae"},"outputs":[],"source":["DATA_DIR = 'data/train/'\n","window_size = 20\n","EPOCHS = 150\n","batch_size=512\n","BUFFER_SIZE=40000\n","acquisition_cost = 50000000\n","cost_reactive = acquisition_cost/3\n","cost_predictive = cost_reactive/3\n","\n","try:\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  %cd /content/drive/MyDrive/Thesis/code/\n","except:\n","  colab = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AtyxLgsZwMYj"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import random \n","from emp.losses.prmc.xgboost import XGBObjectiveFunction, XGBMSE, XGBPseudoHuberLoss\n","from emp.metrics.maintenance import calculate_PRMC\n","import xgboost as xgb\n","from xgboost import XGBRegressor,XGBRFRegressor\n","from sklearn.svm import LinearSVR\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.linear_model import Ridge\n","from sklearn.model_selection import ParameterGrid\n","\n","import json\n","\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from packages.hypopt.model_selection import _compute_score\n","\n","\n","from preprocessing.keras import preprocess_test_windowed_UL, preprocess_train_windowed_UL"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yOhWPfyjZphG"},"outputs":[],"source":["def predict_test_set(model, test_x):\n","    \"\"\"\n","    Simulate the model on the testset. \n","\n","    @test_x: list of numpy arrays representing the observed sensors throughout time\n","    \"\"\"\n","    predicted_RUL_list = []\n","    for machine in test_x:\n","        if 'best_iteration' in dir(model):\n","          # pred_RUL = np.exp(model.predict(machine,iteration_range=(0,model.best_iteration)))\n","          pred_RUL = model.predict(machine,iteration_range=(0,model.best_iteration))\n","          predicted_RUL_list.append(pred_RUL)\n","        else:\n","          # pred_RUL = np.exp(model.predict(machine))\n","          pred_RUL = model.predict(machine)\n","          predicted_RUL_list.append(pred_RUL) \n","    return predicted_RUL_list\n","\n","def unravel_labels_testset(preds):\n","  \"\"\"\n","  Unravel labels into a np.array \n","\n","  Args:\n","      preds (list[np.array]): list of numpy arrays. Each numpy array corresponds to a machine and every value in such array corresponds to \n","                              a prediction for a given moment in time for that specific machine\n","\n","  \"\"\"\n","\n","  out = np.zeros((len(preds),max(list(map(lambda x: len(x),preds)))))\n","  for row, machine in enumerate(preds):\n","      out[row, 0:len(machine)] = np.ravel(machine)\n","\n","  return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LHYH2rxMrI1E"},"outputs":[],"source":["def looper(files,acquisition_cost,cost_reactive,cost_predictive,MODEL_NAME,shared = False,params={\n","    \"verbosity\":1,\n","    'max_depth':6,\n","    'disable_default_eval_metric': 1,\n","    'min_child_weight':1\n","}, epochs = 150,objective=False):\n","  files=files.merge(files.groupby('unit_ID').max('cycles')['cycles'].rename('UL'),left_on='unit_ID',right_index=True)\n","  files['RUL'] = files['UL']-files['cycles'] #create 'RUL-variable' for every row\n","\n","  test_ids = random.sample(list(set(files.unit_ID)),round(len(set(files.unit_ID))*0.1))\n","\n","  test_data = pd.DataFrame()\n","  train_data = files\n","\n","  for test_id in test_ids:\n","      \n","      test_data = pd.concat([test_data,train_data[train_data.unit_ID == test_id]])\n","      train_data = train_data[train_data.unit_ID != test_id]\n","\n","  ## create windowed dataset:\n","  basetable_x, basetable_y, train_UL = preprocess_train_windowed_UL(train_data,window_size=window_size)\n","  train_UL = train_UL.reshape((train_UL.shape[0],))\n","\n","  #calculate cost of rul\n","  cost_RUL = acquisition_cost/train_UL \n","\n","  basetable_y=basetable_y.astype(np.float32)\n","  cost_RUL = cost_RUL.astype(np.float32)\n","  cost_RUL = cost_RUL.reshape((cost_RUL.shape[0],))\n","\n","  if shared:\n","    cost_RUL= np.mean(cost_RUL)\n","  # same for test set:\n","  basetable_x_test, test_y, test_UL = preprocess_test_windowed_UL(test_data,window_size=window_size)\n","  test_UL = [tul.reshape((tul.shape[0],)) for tul in test_UL]\n","  cost_RUL_test = [(acquisition_cost/ul).astype(np.float32) for ul in test_UL] #calculate cost of rul\n","  test_y= [y.astype(np.float32) for y in test_y]\n","\n","  #### Scale & right format for XGB\n","  scaler = StandardScaler()\n","\n","  train_x, train_y = basetable_x,basetable_y\n","  train_x=scaler.fit_transform(train_x.reshape(-1,train_x.shape[-1])).reshape(train_x.shape)\n","  test_x=[scaler.transform(machine.reshape(-1,machine.shape[-1])).reshape(machine.shape) for machine in basetable_x_test]\n","\n","  ## Right format for XGBOOST:\n","  train_x=train_x.reshape(train_x.shape[0],train_x.shape[1]*train_x.shape[2])\n","  test_x=[machine.reshape(machine.shape[0],machine.shape[1]*machine.shape[2]) for machine in test_x]\n","\n","  ## Transform to natural logarithm (to enforce the labels to be strictly positive after e^(pred))\n","  train_y[train_y==0] = 1e-6\n","  # train_y=np.log(train_y)\n","\n","  #DATM\n","  train_datm=xgb.DMatrix(train_x,label=train_y)\n","  test_x=[xgb.DMatrix(item) for item in test_x ]\n","\n","  if not objective:\n","    #obj function, not specified, so choose prmcloss:\n","    objf = XGBObjectiveFunction(cost_reactive, cost_predictive, cost_RUL)\n","  else:\n","    objf = objective\n","  \n","  if type(objf) == str:\n","    bst = xgb.XGBRegressor(params, num_boost_round=epochs, obj=objf)\n","    bst.fit(train_datm)\n","  else:\n","    bst = xgb.train(params, train_datm, num_boost_round=epochs, obj=objf,evals=[(train_datm,'train')], custom_metric=objf.metric)\n","\n","  preds_iter = unravel_labels_testset(predict_test_set(bst,test_x))\n","  trues_iter = unravel_labels_testset(test_y)\n","  cost_rul_iter = np.array([item[0] for item in cost_RUL_test])\n","\n","  try: \n","    with open(f'predictions/m{MODEL_NAME}.pkl','rb') as r:\n","      pk = pickle.load(r)\n","    preds = pk['preds']\n","    trues = pk['trues']\n","    cost_rul = pk['cost_rul']\n","\n","    preds.append(preds_iter)\n","    trues.append(trues_iter)\n","    cost_rul.append(cost_rul_iter)\n","    print('read file & append')\n","  except:\n","    preds = [preds_iter]\n","    trues = [trues_iter]\n","    cost_rul = [cost_rul_iter]\n","    print('file did not exist yet')\n","  finally:\n","    with open(f'predictions/m{MODEL_NAME}.pkl','wb') as w:\n","      pickle.dump({\n","          'preds':preds,\n","          'trues':trues,\n","          'cost_rul':cost_rul,\n","          'cost_reactive':cost_reactive,\n","          'cost_predictive':cost_predictive\n","      },w)\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"czBht1--ZrRa"},"source":["# **Start simulation run:**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z8-KmTs64I4s"},"outputs":[],"source":["def prep_train_val_set(train,validation,window_size=20,name='PRMC'):\n","    train_x, train_y, train_UL = preprocess_train_windowed_UL(train,window_size=window_size)\n","    ##Reshape to the right formats:\n","    train_UL = train_UL.reshape((train_UL.shape[0],))\n","    train_y=train_y.reshape((train_y.shape[0],))\n","    scaler = StandardScaler()\n","    train_x=scaler.fit_transform(train_x.reshape(-1,train_x.shape[-1])).reshape(train_x.shape)\n","    train_x=train_x.reshape(train_x.shape[0],train_x.shape[1]*train_x.shape[2])\n","    if name == 'PRMC':\n","        val_x, val_y, val_UL = preprocess_test_windowed_UL(validation,window_size=window_size)\n","        val_UL = [tul.reshape((tul.shape[0],)) for tul in val_UL]\n","        val_y= [y.astype(np.float32) for y in val_y]\n","        val_x=[scaler.transform(machine.reshape(-1,machine.shape[-1])).reshape(machine.shape) for machine in val_x]\n","        val_x=[machine.reshape(machine.shape[0],machine.shape[1]*machine.shape[2]) for machine in val_x]\n","    else:\n","        val_x, val_y, val_UL = preprocess_train_windowed_UL(validation,window_size=window_size)\n","        val_UL = val_UL.reshape((val_UL.shape[0],))\n","        val_y=val_y.reshape((val_y.shape[0],))\n","        val_x=scaler.transform(val_x.reshape(-1,val_x.shape[-1])).reshape(val_x.shape)\n","        val_x=val_x.reshape(val_x.shape[0],val_x.shape[1]*val_x.shape[2])\n","\n","\n","\n","\n","    return ((train_x, train_y, train_UL), (val_x, val_y, val_UL))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E30P81Lf8_BP"},"outputs":[],"source":["from sklearn.metrics._scorer import _PredictScorer\n","\n","class PRMCScorer(_PredictScorer):\n","    def __init__(self, cost_reactive, cost_predictive, cost_rul, tau=12):\n","        self.tau=tau\n","        self.cost_reactive=cost_reactive\n","        self.cost_predictive=cost_predictive\n","        self.cost_rul=cost_rul\n","    \n","    def __call__(self, estimator, X, y_true):\n","        preds = unravel_labels_testset(predict_test_set(estimator,X))\n","        trues = unravel_labels_testset(y_true)\n","        return np.min([np.sum(calculate_PRMC(preds,trues,self.tau,ti,self.cost_reactive,self.cost_predictive,self.cost_rul)) for ti in np.arange(0,preds.shape[-1])])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1227267,"status":"ok","timestamp":1685464579632,"user":{"displayName":"Samuel Bakker","userId":"04317401039199357493"},"user_tz":-120},"id":"-WJsxi6i4I4u","outputId":"1aadd90f-16a9-45e9-8402-5cee45546186"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of combinations: 1\n","1/1\n"]}],"source":["train = pd.read_csv('data/gold/train.csv')\n","validation = pd.read_csv('data/gold/validation.csv')\n","acquisition_cost=50_000_000\n","\n","# metric_name= 'neg_mean_squared_error'\n","metric_name= 'neg_mean_absolute_error'\n","# metric_name= 'PRMC'\n","\n","\n","# model_name = 'RF'\n","# model_name = 'XGBOOST'\n","# model_name = 'SVR'\n","model_name = 'LR'\n","\n","\n","if model_name == 'XGBOOST':\n","  model = xgb.XGBRegressor()\n","  params={\n","    'max_depth':np.arange(2,6),\n","    'n_estimators':np.arange(100,600,100),\n","    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n","    'subsample': [1, 0.9, 0.8, 0.7],\n","    'colsample_by_tree': [1, 0.9, 0.8, 0.7],\n","    'window_size':[20]\n","    }\n","elif model_name == 'SVR':\n","  model = LinearSVR()\n","  params={\n","      'epsilon':np.arange(6.4,6.7,0.1),\n","      'max_iter':[1000],\n","      'C':np.arange(17,24),\n","      'window_size':[40]\n","  }\n","elif model_name == 'RF':\n","  #For MAE use the XGBOOST implementation!\n","  model=XGBRFRegressor()\n","  params={\n","      'num_parallel_tree':[100],\n","      'eta':[0.1],\n","      'subsample':[0.9],\n","      'colsample_bynode':[0.9],\n","      'window_size':[40],\n","      'max_depth': [15],\n","      'objective': ['reg:absoluteerror'],\n","  }\n","elif model_name == 'LR':\n","  model=Ridge()\n","  params ={\n","      'alpha': np.arange(0,20,0.5),\n","      'max_iter':[100,150,200],\n","      'window_size':[40]\n","  }\n","\n","\n","#save the dataframes to a dict: (else you would need to make them everytime)\n","data=dict()\n","for ws in params['window_size']:\n","    data[str(ws)] = prep_train_val_set(train,validation,ws,name=metric_name)\n","\n","\n","num_combs = len(ParameterGrid(params))\n","print(f\"Number of combinations: {num_combs}\")\n","if metric_name == 'PRMC':\n","  best_eval = np.inf\n","  for iter,params in enumerate(ParameterGrid(params)): \n","    print(f\"{iter+1}/{num_combs}\")\n","    (train,validation)=data[str(params['window_size'])]\n","    window_size = params['window_size']\n","    params.pop('window_size')\n","    model=model.__class__(**params)\n","\n","    model.fit(train[0],train[1])\n","    cost_RUL_val = [(50_000_000/ul).astype(np.float32) for ul in validation[2]] #calculate cost of rul\n","    cost_RUL_val = np.array([item[0] for item in cost_RUL_val]) #keep one cost per machine\n","    prmc=PRMCScorer(50_000_000/3, 50_000_000/9, cost_RUL_val)\n","    new_eval = prmc(model,validation[0],validation[1])\n","    if new_eval < best_eval:\n","      params['window_size']=window_size\n","      best_params = params\n","      best_eval = new_eval\n","else:\n","  best_eval = -np.inf\n","  for iter,params in enumerate(ParameterGrid(params)):\n","    print(f\"{iter+1}/{num_combs}\")\n","    (train,validation)=data[str(params['window_size'])]\n","    window_size = params['window_size']\n","    params.pop('window_size')\n","    model=model.__class__(**params)\n","    model.fit(train[0],train[1])\n","    new_eval = _compute_score(model,validation[0],validation[1],scoring_metric=metric_name)\n","    if new_eval > best_eval:\n","      params['window_size']=window_size\n","      best_params = params\n","      best_eval = new_eval\n","\n","\n","print(f\"#Best parameters: {best_params} Best Validation score: {abs(best_eval)} {metric_name}\")\n","\n","\n","\n","\n","\n"]}],"metadata":{"colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"}},"nbformat":4,"nbformat_minor":0}
